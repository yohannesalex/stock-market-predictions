{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os , sys\n",
    "sys.path.append(os.path.join(os.getcwd(),'..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts.sentiment_labeler import assign_sentiment_label\n",
    "\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/kifiya ai/stock-market-predictions/src/data/raw_analyst_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_data = pd.read_csv('../src/data/yfinance_data/AAPL_historical_data.csv')\n",
    "amazon_data = pd.read_csv('../src/data/yfinance_data/AMZN_historical_data.csv')\n",
    "google_data = pd.read_csv('../src/data/yfinance_data/GOOG_historical_data.csv')\n",
    "meta_data = pd.read_csv('../src/data/yfinance_data/META_historical_data.csv')\n",
    "microsoft_data = pd.read_csv('../src/data/yfinance_data/MSFT_historical_data.csv')\n",
    "nvidia_data = pd.read_csv('../src/data/yfinance_data/NVDA_historical_data.csv')\n",
    "tesla_data = pd.read_csv('../src/data/yfinance_data/TSLA_historical_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05</td>\n",
       "      <td>A</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>A</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>A</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>A</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>A</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           headline  \\\n",
       "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2           2                      71 Biggest Movers From Friday   \n",
       "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       "\n",
       "        date stock sentiment_label  \n",
       "0 2020-06-05     A         Neutral  \n",
       "1 2020-06-03     A         Neutral  \n",
       "2 2020-05-26     A         Neutral  \n",
       "3 2020-05-22     A         Neutral  \n",
       "4 2020-05-22     A         Neutral  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date'] = pd.to_datetime(data['date'],  errors='coerce')\n",
    "data['sentiment_label'] = data['headline'].apply(lambda headline: assign_sentiment_label(TextBlob(headline).sentiment.polarity))\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between news sentiment and stock returns: nan\n"
     ]
    }
   ],
   "source": [
    "# Ensure both columns are in datetime format\n",
    "data['date'] = pd.to_datetime(data['date'], errors='coerce').dt.date\n",
    "tesla_data['Date'] = pd.to_datetime(tesla_data['Date'], errors='coerce').dt.date\n",
    "\n",
    "# Filter the 'data' table where the stock column is 'TSLA'\n",
    "tes_data = data[data['stock'] == 'AMZN']\n",
    "\n",
    "# Merge the filtered table on the cleaned date columns\n",
    "merged_tesla_table = pd.merge(tes_data, tesla_data, left_on='date', right_on='Date', how='inner')\n",
    "\n",
    "# Drop the redundant 'Date' column after merging\n",
    "merged_tesla_table = merged_tesla_table.drop(columns=['Date'])\n",
    "\n",
    "# Calculate percentage change in closing prices\n",
    "merged_tesla_table['Stock_Return'] = merged_tesla_table['Adj Close'].pct_change()\n",
    "\n",
    "# Map Sentiment Scores to Numerical Values\n",
    "# Assuming 'sentiment_label' column contains \"Positive\", \"Neutral\", or \"Negative\"\n",
    "sentiment_mapping = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "merged_tesla_table['sentiment'] = merged_tesla_table['sentiment_label'].map(sentiment_mapping)\n",
    "\n",
    "# Drop rows with NaN values in sentiment or Stock_Return\n",
    "cleaned_data = merged_tesla_table.dropna(subset=['sentiment', 'Stock_Return'])\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = cleaned_data[['sentiment', 'Stock_Return']].corr().iloc[0, 1]\n",
    "print(f'Correlation between news sentiment and stock returns: {correlation}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between news sentiment and stock returns: 0.22941573387056174\n"
     ]
    }
   ],
   "source": [
    "# Ensure both columns are in datetime format\n",
    "data['date'] = pd.to_datetime(data['date'], errors='coerce').dt.date\n",
    "amazon_data['Date'] = pd.to_datetime(amazon_data['Date'], errors='coerce').dt.date\n",
    "\n",
    "# Filter the 'data' table where the stock column is 'TSLA'\n",
    "amaz_data = data[data['stock'] == 'AMZN']\n",
    "\n",
    "# Merge the filtered table on the cleaned date columns\n",
    "merged_amazon_table = pd.merge(amaz_data, amazon_data, left_on='date', right_on='Date', how='inner')\n",
    "\n",
    "# Drop the redundant 'Date' column after merging\n",
    "merged_amazon_table = merged_amazon_table.drop(columns=['Date'])\n",
    "\n",
    "# Calculate percentage change in closing prices\n",
    "merged_amazon_table['Stock_Return'] = merged_amazon_table['Adj Close'].pct_change()\n",
    "\n",
    "# Map Sentiment Scores to Numerical Values\n",
    "# Assuming 'sentiment_label' column contains \"Positive\", \"Neutral\", or \"Negative\"\n",
    "sentiment_mapping = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "merged_amazon_table['sentiment'] = merged_amazon_table['sentiment_label'].map(sentiment_mapping)\n",
    "\n",
    "# Drop rows with NaN values in sentiment or Stock_Return\n",
    "cleaned_data = merged_amazon_table.dropna(subset=['sentiment', 'Stock_Return'])\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = cleaned_data[['sentiment', 'Stock_Return']].corr().iloc[0, 1]\n",
    "print(f'Correlation between news sentiment and stock returns: {correlation}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between news sentiment and stock returns: -0.31622776601683794\n"
     ]
    }
   ],
   "source": [
    "# Ensure both columns are in datetime format\n",
    "data['date'] = pd.to_datetime(data['date'], errors='coerce').dt.date\n",
    "apple_data['Date'] = pd.to_datetime(apple_data['Date'], errors='coerce').dt.date\n",
    "\n",
    "# Filter the 'data' table where the stock column is 'TSLA'\n",
    "app_data = data[data['stock'] == 'AAPL']\n",
    "\n",
    "# Merge the filtered table on the cleaned date columns\n",
    "merged_apple_table = pd.merge(app_data, apple_data, left_on='date', right_on='Date', how='inner')\n",
    "\n",
    "# Drop the redundant 'Date' column after merging\n",
    "merged_apple_table = merged_apple_table.drop(columns=['Date'])\n",
    "\n",
    "# Calculate percentage change in closing prices\n",
    "merged_apple_table['Stock_Return'] = merged_apple_table['Adj Close'].pct_change()\n",
    "\n",
    "# Map Sentiment Scores to Numerical Values\n",
    "# Assuming 'sentiment_label' column contains \"Positive\", \"Neutral\", or \"Negative\"\n",
    "sentiment_mapping = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "merged_apple_table['sentiment'] = merged_apple_table['sentiment_label'].map(sentiment_mapping)\n",
    "\n",
    "# Drop rows with NaN values in sentiment or Stock_Return\n",
    "cleaned_data = merged_apple_table.dropna(subset=['sentiment', 'Stock_Return'])\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = cleaned_data[['sentiment', 'Stock_Return']].corr().iloc[0, 1]\n",
    "print(f'Correlation between news sentiment and stock returns: {correlation}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between news sentiment and stock returns: nan\n"
     ]
    }
   ],
   "source": [
    "# Ensure both columns are in datetime format\n",
    "data['date'] = pd.to_datetime(data['date'], errors='coerce').dt.date\n",
    "microsoft_data['Date'] = pd.to_datetime(microsoft_data['Date'], errors='coerce').dt.date\n",
    "\n",
    "# Filter the 'data' table where the stock column is 'TSLA'\n",
    "mic_data = data[data['stock'] == 'MSFT']\n",
    "\n",
    "# Merge the filtered table on the cleaned date columns\n",
    "merged_microsoft_table = pd.merge(mic_data, microsoft_data, left_on='date', right_on='Date', how='inner')\n",
    "\n",
    "# Drop the redundant 'Date' column after merging\n",
    "merged_microsoft_table = merged_microsoft_table.drop(columns=['Date'])\n",
    "\n",
    "# Calculate percentage change in closing prices\n",
    "merged_microsoft_table['Stock_Return'] = merged_microsoft_table['Adj Close'].pct_change()\n",
    "\n",
    "# Map Sentiment Scores to Numerical Values\n",
    "# Assuming 'sentiment_label' column contains \"Positive\", \"Neutral\", or \"Negative\"\n",
    "sentiment_mapping = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "merged_microsoft_table['sentiment'] = merged_microsoft_table['sentiment_label'].map(sentiment_mapping)\n",
    "\n",
    "# Drop rows with NaN values in sentiment or Stock_Return\n",
    "cleaned_data = merged_microsoft_table.dropna(subset=['sentiment', 'Stock_Return'])\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = cleaned_data[['sentiment', 'Stock_Return']].corr().iloc[0, 1]\n",
    "print(f'Correlation between news sentiment and stock returns: {correlation}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between news sentiment and stock returns: -0.08308662177227347\n"
     ]
    }
   ],
   "source": [
    "# Ensure both columns are in datetime format\n",
    "data['date'] = pd.to_datetime(data['date'], errors='coerce').dt.date\n",
    "google_data['Date'] = pd.to_datetime(google_data['Date'], errors='coerce').dt.date\n",
    "\n",
    "# Filter the 'data' table where the stock column is 'TSLA'\n",
    "goog_data = data[data['stock'] == 'GOOG']\n",
    "\n",
    "# Merge the filtered table on the cleaned date columns\n",
    "merged_google_table = pd.merge(goog_data, google_data, left_on='date', right_on='Date', how='inner')\n",
    "\n",
    "# Drop the redundant 'Date' column after merging\n",
    "merged_google_table = merged_google_table.drop(columns=['Date'])\n",
    "\n",
    "# Calculate percentage change in closing prices\n",
    "merged_google_table['Stock_Return'] = merged_google_table['Adj Close'].pct_change()\n",
    "\n",
    "# Map Sentiment Scores to Numerical Values\n",
    "# Assuming 'sentiment_label' column contains \"Positive\", \"Neutral\", or \"Negative\"\n",
    "sentiment_mapping = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "merged_google_table['sentiment'] = merged_google_table['sentiment_label'].map(sentiment_mapping)\n",
    "\n",
    "# Drop rows with NaN values in sentiment or Stock_Return\n",
    "cleaned_data = merged_google_table.dropna(subset=['sentiment', 'Stock_Return'])\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = cleaned_data[['sentiment', 'Stock_Return']].corr().iloc[0, 1]\n",
    "print(f'Correlation between news sentiment and stock returns: {correlation}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between news sentiment and stock returns: -0.2635131877859457\n"
     ]
    }
   ],
   "source": [
    "# Ensure both columns are in datetime format\n",
    "data['date'] = pd.to_datetime(data['date'], errors='coerce').dt.date\n",
    "nvidia_data['Date'] = pd.to_datetime(nvidia_data['Date'], errors='coerce').dt.date\n",
    "\n",
    "# Filter the 'data' table where the stock column is 'TSLA'\n",
    "nvi_data = data[data['stock'] == 'GOOG']\n",
    "\n",
    "# Merge the filtered table on the cleaned date columns\n",
    "merged_nvidia_table = pd.merge(nvi_data, nvidia_data, left_on='date', right_on='Date', how='inner')\n",
    "\n",
    "# Drop the redundant 'Date' column after merging\n",
    "merged_nvidia_table = merged_nvidia_table.drop(columns=['Date'])\n",
    "\n",
    "# Calculate percentage change in closing prices\n",
    "merged_nvidia_table['Stock_Return'] = merged_nvidia_table['Adj Close'].pct_change()\n",
    "\n",
    "# Map Sentiment Scores to Numerical Values\n",
    "# Assuming 'sentiment_label' column contains \"Positive\", \"Neutral\", or \"Negative\"\n",
    "sentiment_mapping = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "merged_nvidia_table['sentiment'] = merged_nvidia_table['sentiment_label'].map(sentiment_mapping)\n",
    "\n",
    "# Drop rows with NaN values in sentiment or Stock_Return\n",
    "cleaned_data = merged_nvidia_table.dropna(subset=['sentiment', 'Stock_Return'])\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = cleaned_data[['sentiment', 'Stock_Return']].corr().iloc[0, 1]\n",
    "print(f'Correlation between news sentiment and stock returns: {correlation}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
